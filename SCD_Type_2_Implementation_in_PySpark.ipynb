{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCD Type 2 Implementation in PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLktukWgGHgwxfqewJWes/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capt-blackdron/pyspark-examples/blob/main/SCD_Type_2_Implementation_in_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x1BCzjEQD0m"
      },
      "source": [
        "**Setting up Hadoop and Pyspark **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0qcjenTMVu"
      },
      "source": [
        "SCD Type 2 EXAMPLE CODE : Strategy: Maintain history of record (versions) if match is found in new dataset and insert new records if do not exist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN1ISgFO3vUr"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqA55wtV5g7H"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install pyspark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9OS59f7ZZdr"
      },
      "source": [
        "**First Create a Target Table** \n",
        "\n",
        "`create external table dev_db.employee(emp_id int, emp_name string, email_id string, state string, eff_date date, end_date date, is_current varchar(2)) stored as ORC location 'hdfs_path';`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNeU2zLqUHAE",
        "outputId": "f5fbff95-aa22-4e50-9e0e-1c2615da5c9a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SCD1_DEMO\").getOrCreate()\n",
        "\n",
        "# load_date value will be '2021-07-01' when the first time you run\n",
        "# You can pass load_date to spark program through command line arguments\n",
        "# load_date = sys.argv[1] #2021-07-01\n",
        "# for testing I have hardcoded this value\n",
        "load_date = '2021-07-01'\n",
        "target_table = 'employee'\n",
        "max_date = '9999-12-31'\n",
        "\n",
        "# we cannot use Hive in colab that's why I am saving this dataframe as a table here...\n",
        "# Assume you have created a hive table using 'create table ' command\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/Colab Notebooks/emp_data_{}.csv\".format(load_date), header=True)\\\n",
        "        .withColumn('eff_date', lit(load_date).cast('date'))\\\n",
        "        .withColumn('end_date', lit(max_date).cast('date'))\\\n",
        "        .withColumn('is_current', lit('Y'))\n",
        "\n",
        "df.createOrReplaceTempView('target_table_view')\n",
        "spark.sql(\"create table if not exists {} like target_table_view\".format(target_table))\n",
        "spark.read.table(target_table).printSchema()\n",
        "print(\"Empty target table created...\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- emp_id: string (nullable = true)\n",
            " |-- emp_name: string (nullable = true)\n",
            " |-- email_id: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- eff_date: date (nullable = true)\n",
            " |-- end_date: date (nullable = true)\n",
            " |-- is_current: string (nullable = true)\n",
            "\n",
            "Empty target table created...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNtsAZ0bfSge",
        "outputId": "2afce6bb-4737-465a-e6c3-1aeb6cee2abf"
      },
      "source": [
        "#below 4 lines are for testing purpose as on next run data will already exist in colab\n",
        "#insert overwrite is not supported in colab for same table..\n",
        "#so here I am creating an empty table\n",
        "spark.sql(\"drop table if exists employee_temp\")\n",
        "spark.sql(\"create table employee_temp like employee\")\n",
        "spark.sql(\"drop table if exists employee\")\n",
        "spark.sql(\"alter table employee_temp rename to employee\")\n",
        "\n",
        "def load_data(load_date):\n",
        "  print(\"Performing data load for '{}'\".format(load_date))\n",
        "  \n",
        "  max_date = '9999-12-31'\n",
        "  target_table = 'employee'\n",
        "\n",
        "  # step 1 -- read the current date data from file \n",
        "  current_df = spark.read.csv(\"/content/drive/MyDrive/Colab Notebooks/emp_data_{}.csv\".format(load_date), header=True)\\\n",
        "          .withColumn('eff_date', lit(load_date).cast('date'))\\\n",
        "          .withColumn('end_date', lit(max_date).cast('date'))\\\n",
        "          .withColumn('is_current', lit('Y'))\n",
        "          \n",
        "  # step 2 -- read target table data \n",
        "  # Read active records only \n",
        "  target_df = spark.read.table(target_table)\\\n",
        "              .filter(col('is_current')=='Y')\n",
        "  \n",
        "  # for the first load target_df will not have any records \n",
        "\n",
        "  current_df = current_df.select(col('emp_id').alias('emp_id_right'), col('emp_name').alias('emp_name_right'),\n",
        "                col('email_id').alias('email_id_right'), col('state').alias('state_right'),\n",
        "                 col('eff_date').alias('eff_date_right'), col('end_date').alias('end_date_right'), \n",
        "                 col('is_current').alias('is_current_right'))\n",
        "\n",
        "  '''\n",
        "  ACTION - INSERT : New data is inserted if no match is found in target table and insert into final table (check left column)\n",
        "  ACTION - Update : Old records are updated in target table if new data is found (maintain version) (join key in the right must not be null)\n",
        "  ACTION - AS IS / No change : Old records are inserted into target if no match found (if join key in the right is null then keep data as is)  \n",
        "  '''\n",
        "\n",
        "  ''' \n",
        "  step 3 -- Derive action_flag\n",
        "  '''\n",
        "\n",
        "  merged_df = target_df.join(current_df, target_df.emp_id == current_df.emp_id_right, 'full')\\\n",
        "                .withColumn('action_flag', when(target_df.emp_id.isNull(), 'insert')\\\n",
        "                                          .when(current_df.emp_id_right.isNull(), 'no_change')\\\n",
        "                                          .when(current_df.emp_id_right.isNotNull(), 'update'))\n",
        "  \n",
        "  # records which are not present in target table, but came in current load for the first time will be tagged as \"insert\"\n",
        "  insert_df = merged_df.filter(col('action_flag') == 'insert')\\\n",
        "              .select('emp_id_right', 'emp_name_right', 'email_id_right', 'state_right', 'eff_date_right', 'end_date_right', 'is_current_right')\n",
        "\n",
        "  # records from target table that got no match in new data, these records will be tagged as \"no change\"\n",
        "  no_change_df = merged_df.filter(col('action_flag') == 'no_change')\\\n",
        "              .select('emp_id', 'emp_name', 'email_id', 'state', 'eff_date', 'end_date', 'is_current')\n",
        "\n",
        "  update_df = merged_df.filter(col('action_flag') == 'update')\n",
        "  \n",
        "  #detect change and filter changed records and process\n",
        "  #insert no change detected records as is\n",
        "\n",
        "  update_df = update_df.withColumn('is_changed', when(((update_df.emp_name!=update_df.emp_name_right)\n",
        "                                                    | (update_df.email_id!=update_df.email_id_right)\n",
        "                                                    | (update_df.state!=update_df.state_right)), lit('Y')).otherwise(lit('N')))\\\n",
        "                      \n",
        "                      \n",
        "  change_detected_df = update_df.filter(col('is_changed')=='Y')\n",
        "  \n",
        "  #we got new records in file matching with old records,\n",
        "  #but column values were not changed, these records will be tagged as \"no changed detected\"\n",
        "  \n",
        "  no_change_detected_df = update_df.filter(col('is_changed')=='N')\\\n",
        "                      .select('emp_id', 'emp_name', 'email_id', 'state', 'eff_date', 'end_date', 'is_current')\n",
        "\n",
        "  #we got new records in current load and few columns values were changed, will be processed below\n",
        "  #marking old records as obsolete: is_current='N'\n",
        "  #updated end date as (Day - 1) \n",
        "  update_df_history = change_detected_df.select('emp_id', 'emp_name', 'email_id', 'state', 'eff_date', \n",
        "                                       date_add(lit(load_date),-1).alias('end_date'),\n",
        "                                       lit('N').alias('is_current'))\n",
        "  \n",
        "  updated_records = change_detected_df.withColumn('emp_name', when(col('emp_name_right').isNotNull(), col('emp_name_right')).otherwise(col('emp_name')))\\\n",
        "                      .withColumn('email_id', when(col('email_id_right').isNotNull(), col('email_id_right')).otherwise(col('email_id')))\\\n",
        "                      .withColumn('state', when(col('state_right').isNotNull(), col('state_right')).otherwise(col('state')))\\\n",
        "                      .select('emp_id', 'emp_name', 'email_id', 'state', 'eff_date_right', 'end_date_right', 'is_current_right')\n",
        "  \n",
        "  final_df = insert_df.union(no_change_df).union(no_change_detected_df).union(update_df_history).union(updated_records)  \n",
        "\n",
        "  # carrying inactive records \n",
        "  # please note in Step 1 we have read only active records from target table\n",
        "  inactive_records = spark.read.table(target_table)\\\n",
        "              .filter(col('is_current')=='N')\n",
        "\n",
        "  final_df = inactive_records.union(final_df)\n",
        "  \n",
        "\n",
        "  # step 4 -- write final_df to target table (not supported in colab)\n",
        "  # final_df.write.mode('overwrite').saveAsTable(target_table)\n",
        "\n",
        "  #below three lines are for testing purpose as overwrite to same table is not supported in colab\n",
        "  temp_table = 'employee_temp'\n",
        "  final_df.write.mode('overwrite').saveAsTable(temp_table)\n",
        "  spark.sql(\"insert overwrite table {} select * from {}\".format(target_table, temp_table))\n",
        "\n",
        "  print(\"Data loaded for '{}'\".format(load_date))\n",
        "  print(\"Target Table\")\n",
        "  spark.read.table(target_table).orderBy(col('emp_id').cast('int'), col('eff_date')).show(100)\n",
        "  \n",
        "load_data('2021-07-01')\n",
        "load_data('2021-07-02')\n",
        "load_data('2021-07-03')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing data load for '2021-07-01'\n",
            "Data loaded for '2021-07-01'\n",
            "Target Table\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|emp_id|            emp_name|            email_id|state|  eff_date|  end_date|is_current|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|     1|       Denis Hagenes|leroy83@runolfsdo...|   AS|2021-07-01|9999-12-31|         Y|\n",
            "|     2|Shiela Altenwerth...|ialtenwerth@rolfs...|   GA|2021-07-01|9999-12-31|         Y|\n",
            "|     3| Elois Marquardt PhD|cornel12@hotmail.com|   MN|2021-07-01|9999-12-31|         Y|\n",
            "|     4|       Leila Simonis|lidie39@satterfie...|   NC|2021-07-01|9999-12-31|         Y|\n",
            "|     5|       Jerri Spencer|wolffkatarina@hot...|   LA|2021-07-01|9999-12-31|         Y|\n",
            "|     6|Dr. Drusilla Olso...|concepcion18@hotm...|   NE|2021-07-01|9999-12-31|         Y|\n",
            "|     7| Dr. Cade Shields MD|clevie31@hotmail.com|   CT|2021-07-01|9999-12-31|         Y|\n",
            "|     8|Mr. Maximo Bayer DDS|johnsonbelva@yaho...|   DC|2021-07-01|9999-12-31|         Y|\n",
            "|     9|  Doctor Considine I|jamiereynolds@bar...|   NH|2021-07-01|9999-12-31|         Y|\n",
            "|    10|           Sky Towne| margret22@gmail.com|   MD|2021-07-01|9999-12-31|         Y|\n",
            "|    11|           Leta Koch|beerkimberlee@hot...|   VT|2021-07-01|9999-12-31|         Y|\n",
            "|    12|        Adison Lemke|jacquelinestanton...|   WV|2021-07-01|9999-12-31|         Y|\n",
            "|    13|         Kadin Kulas|  vhegmann@gmail.com|   GU|2021-07-01|9999-12-31|         Y|\n",
            "|    14|        Leann Hirthe|kylehudson@hudson...|   PW|2021-07-01|9999-12-31|         Y|\n",
            "|    15| Windell Cruickshank|hhodkiewicz@lemke...|   CO|2021-07-01|9999-12-31|         Y|\n",
            "|    16|Miss Michal Carte...|    elam85@gmail.com|   MN|2021-07-01|9999-12-31|         Y|\n",
            "|    17|      Yolanda Kirlin|rodryan@koss-damo...|   OK|2021-07-01|9999-12-31|         Y|\n",
            "|    18|         Loni Senger|clueilwitz@muelle...|   MO|2021-07-01|9999-12-31|         Y|\n",
            "|    19|         Fritz Moore|  bmante@hotmail.com|   WY|2021-07-01|9999-12-31|         Y|\n",
            "|    20|Dr. Kurt Murazik DDS|lucacummerata@run...|   NH|2021-07-01|9999-12-31|         Y|\n",
            "|    21| Mr. Delano Ratke IV|monahanamirah@lem...|   KY|2021-07-01|9999-12-31|         Y|\n",
            "|    22|         Corie Kling|avonrueden@connel...|   GU|2021-07-01|9999-12-31|         Y|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "\n",
            "Performing data load for '2021-07-02'\n",
            "Data loaded for '2021-07-02'\n",
            "Target Table\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|emp_id|            emp_name|            email_id|state|  eff_date|  end_date|is_current|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|     1|       Denis Hagenes|leroy83@runolfsdo...|   AS|2021-07-01|9999-12-31|         Y|\n",
            "|     2|Shiela Altenwerth...|ialtenwerth@rolfs...|   GA|2021-07-01|2021-07-01|         N|\n",
            "|     2|Shiela Altenwerth...| kennard18@gmail.com|   GA|2021-07-02|9999-12-31|         Y|\n",
            "|     3| Elois Marquardt PhD|cornel12@hotmail.com|   MN|2021-07-01|2021-07-01|         N|\n",
            "|     3| Elois Marquardt PhD|starling15@herman...|   IN|2021-07-02|9999-12-31|         Y|\n",
            "|     4|       Leila Simonis|lidie39@satterfie...|   NC|2021-07-01|2021-07-01|         N|\n",
            "|     4|       Leila Simonis|kohlerjacey@king-...|   GA|2021-07-02|9999-12-31|         Y|\n",
            "|     5|       Jerri Spencer|wolffkatarina@hot...|   LA|2021-07-01|9999-12-31|         Y|\n",
            "|     6|Dr. Drusilla Olso...|concepcion18@hotm...|   NE|2021-07-01|9999-12-31|         Y|\n",
            "|     7| Dr. Cade Shields MD|clevie31@hotmail.com|   CT|2021-07-01|9999-12-31|         Y|\n",
            "|     8|Mr. Maximo Bayer DDS|johnsonbelva@yaho...|   DC|2021-07-01|9999-12-31|         Y|\n",
            "|     9|  Doctor Considine I|jamiereynolds@bar...|   NH|2021-07-01|9999-12-31|         Y|\n",
            "|    10|           Sky Towne| margret22@gmail.com|   MD|2021-07-01|9999-12-31|         Y|\n",
            "|    11|           Leta Koch|beerkimberlee@hot...|   VT|2021-07-01|9999-12-31|         Y|\n",
            "|    12|        Adison Lemke|jacquelinestanton...|   WV|2021-07-01|9999-12-31|         Y|\n",
            "|    13|         Kadin Kulas|  vhegmann@gmail.com|   GU|2021-07-01|2021-07-01|         N|\n",
            "|    13|         Kadin Kulas|brennen37@swift-s...|   PW|2021-07-02|9999-12-31|         Y|\n",
            "|    14|        Leann Hirthe|kylehudson@hudson...|   PW|2021-07-01|9999-12-31|         Y|\n",
            "|    15| Windell Cruickshank|hhodkiewicz@lemke...|   CO|2021-07-01|2021-07-01|         N|\n",
            "|    15| Windell Cruickshank|    ukoepp@gmail.com|   AS|2021-07-02|9999-12-31|         Y|\n",
            "|    16|Miss Michal Carte...|    elam85@gmail.com|   MN|2021-07-01|9999-12-31|         Y|\n",
            "|    17|      Yolanda Kirlin|rodryan@koss-damo...|   OK|2021-07-01|9999-12-31|         Y|\n",
            "|    18|         Loni Senger|clueilwitz@muelle...|   MO|2021-07-01|9999-12-31|         Y|\n",
            "|    19|         Fritz Moore|  bmante@hotmail.com|   WY|2021-07-01|9999-12-31|         Y|\n",
            "|    20|Dr. Kurt Murazik DDS|lucacummerata@run...|   NH|2021-07-01|9999-12-31|         Y|\n",
            "|    21| Mr. Delano Ratke IV|monahanamirah@lem...|   KY|2021-07-01|9999-12-31|         Y|\n",
            "|    22|         Corie Kling|avonrueden@connel...|   GU|2021-07-01|9999-12-31|         Y|\n",
            "|    23|       Casen Keebler|rutherforderastus...|   MI|2021-07-02|9999-12-31|         Y|\n",
            "|    24|      Hernan McClure|sunnyschaden@fish...|   ID|2021-07-02|9999-12-31|         Y|\n",
            "|    25|         Odus Turner|alisonyost@hotmai...|   VI|2021-07-02|9999-12-31|         Y|\n",
            "|    26|           Era Rohan|jonatanschroeder@...|   NJ|2021-07-02|9999-12-31|         Y|\n",
            "|    27|      Marcos Pollich|bradhomenick@absh...|   IL|2021-07-02|9999-12-31|         Y|\n",
            "|    28|Dr. Al Stiedemann...| charles24@yahoo.com|   WY|2021-07-02|9999-12-31|         Y|\n",
            "|    29|       Stanton Morar|matilda31@hotmail...|   NV|2021-07-02|9999-12-31|         Y|\n",
            "|    30|     Trevin Ebert II|gleichnermatthias...|   PW|2021-07-02|9999-12-31|         Y|\n",
            "|    31|        Regan Gibson|  noemie83@gmail.com|   AZ|2021-07-02|9999-12-31|         Y|\n",
            "|    32|      Tinie O'Conner|antione35@quitzon...|   CA|2021-07-02|9999-12-31|         Y|\n",
            "|    33| Dr. Aracely Orn DVM|padbergivan@beier...|   MP|2021-07-02|9999-12-31|         Y|\n",
            "|    34|Dr. Alessandro La...|derrellbins@gmail...|   ID|2021-07-02|9999-12-31|         Y|\n",
            "|    35| Dr. Willian Johnson|loveymorar@tillma...|   WY|2021-07-02|9999-12-31|         Y|\n",
            "|    36|   Lashonda Lemke MD|kiefer85@stokes-h...|   AL|2021-07-02|9999-12-31|         Y|\n",
            "|    37|Miss Justina Schi...| lschoen@hotmail.com|   FM|2021-07-02|9999-12-31|         Y|\n",
            "|    38|    Ozzie Labadie IV| demonte53@upton.org|   KY|2021-07-02|9999-12-31|         Y|\n",
            "|    39|        Haden Legros|dgreenfelder@hotm...|   AS|2021-07-02|9999-12-31|         Y|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "\n",
            "Performing data load for '2021-07-03'\n",
            "Data loaded for '2021-07-03'\n",
            "Target Table\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|emp_id|            emp_name|            email_id|state|  eff_date|  end_date|is_current|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "|     1|       Denis Hagenes|leroy83@runolfsdo...|   AS|2021-07-01|2021-07-02|         N|\n",
            "|     1|       Denis Hagenes|tgyfff67@runolfsd...|   AS|2021-07-03|9999-12-31|         Y|\n",
            "|     2|Shiela Altenwerth...|ialtenwerth@rolfs...|   GA|2021-07-01|2021-07-01|         N|\n",
            "|     2|Shiela Altenwerth...| kennard18@gmail.com|   GA|2021-07-02|2021-07-02|         N|\n",
            "|     2|Shiela Altenwerth...| kennard18@gmail.com|   US|2021-07-03|9999-12-31|         Y|\n",
            "|     3| Elois Marquardt PhD|cornel12@hotmail.com|   MN|2021-07-01|2021-07-01|         N|\n",
            "|     3| Elois Marquardt PhD|starling15@herman...|   IN|2021-07-02|9999-12-31|         Y|\n",
            "|     4|       Leila Simonis|lidie39@satterfie...|   NC|2021-07-01|2021-07-01|         N|\n",
            "|     4|       Leila Simonis|kohlerjacey@king-...|   GA|2021-07-02|9999-12-31|         Y|\n",
            "|     5|       Jerri Spencer|wolffkatarina@hot...|   LA|2021-07-01|2021-07-02|         N|\n",
            "|     5|       Jerri Spencer|wolffkatarina@gma...|   LA|2021-07-03|9999-12-31|         Y|\n",
            "|     6|Dr. Drusilla Olso...|concepcion18@hotm...|   NE|2021-07-01|9999-12-31|         Y|\n",
            "|     7| Dr. Cade Shields MD|clevie31@hotmail.com|   CT|2021-07-01|2021-07-02|         N|\n",
            "|     7|         Dr. Cade MD|clevie31@hotmail.com|   CT|2021-07-03|9999-12-31|         Y|\n",
            "|     8|Mr. Maximo Bayer DDS|johnsonbelva@yaho...|   DC|2021-07-01|9999-12-31|         Y|\n",
            "|     9|  Doctor Considine I|jamiereynolds@bar...|   NH|2021-07-01|2021-07-02|         N|\n",
            "|     9|            Doctor I|jamiereynolds@bar...|   NH|2021-07-03|9999-12-31|         Y|\n",
            "|    10|           Sky Towne| margret22@gmail.com|   MD|2021-07-01|2021-07-02|         N|\n",
            "|    10|           Sky Towne| gukipolt5@gmail.com|   MD|2021-07-03|9999-12-31|         Y|\n",
            "|    11|           Leta Koch|beerkimberlee@hot...|   VT|2021-07-01|9999-12-31|         Y|\n",
            "|    12|        Adison Lemke|jacquelinestanton...|   WV|2021-07-01|9999-12-31|         Y|\n",
            "|    13|         Kadin Kulas|  vhegmann@gmail.com|   GU|2021-07-01|2021-07-01|         N|\n",
            "|    13|         Kadin Kulas|brennen37@swift-s...|   PW|2021-07-02|9999-12-31|         Y|\n",
            "|    14|        Leann Hirthe|kylehudson@hudson...|   PW|2021-07-01|9999-12-31|         Y|\n",
            "|    15| Windell Cruickshank|hhodkiewicz@lemke...|   CO|2021-07-01|2021-07-01|         N|\n",
            "|    15| Windell Cruickshank|    ukoepp@gmail.com|   AS|2021-07-02|9999-12-31|         Y|\n",
            "|    16|Miss Michal Carte...|    elam85@gmail.com|   MN|2021-07-01|9999-12-31|         Y|\n",
            "|    17|      Yolanda Kirlin|rodryan@koss-damo...|   OK|2021-07-01|9999-12-31|         Y|\n",
            "|    18|         Loni Senger|clueilwitz@muelle...|   MO|2021-07-01|9999-12-31|         Y|\n",
            "|    19|         Fritz Moore|  bmante@hotmail.com|   WY|2021-07-01|9999-12-31|         Y|\n",
            "|    20|Dr. Kurt Murazik DDS|lucacummerata@run...|   NH|2021-07-01|9999-12-31|         Y|\n",
            "|    21| Mr. Delano Ratke IV|monahanamirah@lem...|   KY|2021-07-01|9999-12-31|         Y|\n",
            "|    22|         Corie Kling|avonrueden@connel...|   GU|2021-07-01|9999-12-31|         Y|\n",
            "|    23|       Casen Keebler|rutherforderastus...|   MI|2021-07-02|9999-12-31|         Y|\n",
            "|    24|      Hernan McClure|sunnyschaden@fish...|   ID|2021-07-02|9999-12-31|         Y|\n",
            "|    25|         Odus Turner|alisonyost@hotmai...|   VI|2021-07-02|9999-12-31|         Y|\n",
            "|    26|           Era Rohan|jonatanschroeder@...|   NJ|2021-07-02|9999-12-31|         Y|\n",
            "|    27|      Marcos Pollich|bradhomenick@absh...|   IL|2021-07-02|9999-12-31|         Y|\n",
            "|    28|Dr. Al Stiedemann...| charles24@yahoo.com|   WY|2021-07-02|9999-12-31|         Y|\n",
            "|    29|       Stanton Morar|matilda31@hotmail...|   NV|2021-07-02|9999-12-31|         Y|\n",
            "|    30|     Trevin Ebert II|gleichnermatthias...|   PW|2021-07-02|9999-12-31|         Y|\n",
            "|    31|        Regan Gibson|  noemie83@gmail.com|   AZ|2021-07-02|9999-12-31|         Y|\n",
            "|    32|      Tinie O'Conner|antione35@quitzon...|   CA|2021-07-02|9999-12-31|         Y|\n",
            "|    33| Dr. Aracely Orn DVM|padbergivan@beier...|   MP|2021-07-02|9999-12-31|         Y|\n",
            "|    34|Dr. Alessandro La...|derrellbins@gmail...|   ID|2021-07-02|9999-12-31|         Y|\n",
            "|    35| Dr. Willian Johnson|loveymorar@tillma...|   WY|2021-07-02|9999-12-31|         Y|\n",
            "|    36|   Lashonda Lemke MD|kiefer85@stokes-h...|   AL|2021-07-02|9999-12-31|         Y|\n",
            "|    37|Miss Justina Schi...| lschoen@hotmail.com|   FM|2021-07-02|9999-12-31|         Y|\n",
            "|    38|    Ozzie Labadie IV| demonte53@upton.org|   KY|2021-07-02|9999-12-31|         Y|\n",
            "|    39|        Haden Legros|dgreenfelder@hotm...|   AS|2021-07-02|9999-12-31|         Y|\n",
            "+------+--------------------+--------------------+-----+----------+----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}